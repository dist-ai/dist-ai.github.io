<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog - MLC</title>
    <link rel="stylesheet" href="css/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <script src="js/includes.js" defer></script>
</head>
<body>
    <div id="site-header"></div>

    <main>
        <!-- Page Header -->
        <section class="page-header">
            <div class="container">
                <h1 class="page-title">Blog</h1>
                <p class="page-description">
                    Stay updated with the latest developments, tutorials, and insights 
                    from the MLC-LLM community and development team.
                </p>
            </div>
        </section>

        <!-- Featured Article -->
        <section class="featured-article">
            <div class="container">
                <div class="featured-card">
                    <div class="featured-content">
                        <div class="featured-badge">
                            <i class="fas fa-star"></i>
                            <span>Latest</span>
                        </div>
                        <h2>Microserving LLM engines</h2>
                        <p class="featured-excerpt">
                            Explore microserving architectures for large language model engines, enabling efficient 
                            deployment and scaling of LLM inference services across diverse infrastructure environments.
                        </p>
                        <div class="featured-meta">
                            <span class="author">
                                <i class="fas fa-user"></i>
                                MLC Team
                            </span>
                            <span class="date">
                                <i class="fas fa-calendar"></i>
                                January 7, 2025
                            </span>
                            <span class="read-time">
                                <i class="fas fa-clock"></i>
                                10 min read
                            </span>
                        </div>
                        <a href="https://blog.mlc.ai/2025/01/07/microserving-llm-engines" class="btn btn-primary" target="_blank" rel="noopener">Read Full Article</a>
                    </div>
                    <div class="featured-visual">
                        <div class="performance-chart">
                            <div class="chart-header">
                                <h4>Blog Posts</h4>
                                <span class="chart-subtitle">Latest Updates</span>
                            </div>
                            <div class="chart-bars">
                                <div class="bar-item">
                                    <span class="bar-label">Total Posts</span>
                                    <div class="bar-container">
                                        <div class="bar-fill" style="width: 100%; background: var(--primary-color);">
                                            <span class="bar-value">11</span>
                                        </div>
                                    </div>
                                </div>
                                <div class="bar-item">
                                    <span class="bar-label">2024 Posts</span>
                                    <div class="bar-container">
                                        <div class="bar-fill" style="width: 73%; background: var(--accent-color);">
                                            <span class="bar-value">8</span>
                                        </div>
                                    </div>
                                </div>
                                <div class="bar-item">
                                    <span class="bar-label">2025 Posts</span>
                                    <div class="bar-container">
                                        <div class="bar-fill" style="width: 9%; background: var(--secondary-color);">
                                            <span class="bar-value">1</span>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Blog Categories -->
        <section class="blog-categories">
            <div class="container">
                <div class="categories-filter">
                    <button class="category-btn active" data-category="all">All Posts</button>
                    <button class="category-btn" data-category="research">Research</button>
                    <button class="category-btn" data-category="tutorials">Tutorials</button>
                    <button class="category-btn" data-category="deployment">Deployment</button>
                    <button class="category-btn" data-category="optimization">Optimization</button>
                </div>
            </div>
        </section>

        <!-- Blog Posts Grid -->
        <section class="blog-posts">
            <div class="container">
                <div class="posts-grid">
                    <!-- Article 1: Microserving LLM engines -->
                    <article class="blog-card" data-category="deployment">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fas fa-server"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Deployment</span>
                                <span class="blog-date">January 7, 2025</span>
                            </div>
                            <h3>Microserving LLM engines</h3>
                            <p>Explore microserving architectures for large language model engines, enabling efficient deployment and scaling of LLM inference services.</p>
                            <div class="blog-footer">
                                <span class="read-time">10 min read</span>
                                <a href="https://blog.mlc.ai/2025/01/07/microserving-llm-engines" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>

                    <!-- Article 2: XGrammar -->
                    <article class="blog-card" data-category="research">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fas fa-magic"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Research</span>
                                <span class="blog-date">November 22, 2024</span>
                            </div>
                            <h3>Achieving Efficient, Flexible, and Portable Structured Generation with XGrammar</h3>
                            <p>Discover XGrammar, a system for efficient structured generation that enables flexible and portable constrained decoding with expressive grammars.</p>
                            <div class="blog-footer">
                                <span class="read-time">12 min read</span>
                                <a href="https://blog.mlc.ai/2024/11/22/achieving-efficient-flexible-portable-structured-generation-with-xgrammar" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>

                    <!-- Article 3: MLCEngine Optimization -->
                    <article class="blog-card" data-category="optimization">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fas fa-tachometer-alt"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Optimization</span>
                                <span class="blog-date">October 10, 2024</span>
                            </div>
                            <h3>Optimizing and Characterizing High-Throughput Low-Latency LLM Inference in MLCEngine</h3>
                            <p>Deep dive into optimization techniques and performance characterization for achieving high-throughput and low-latency LLM inference in MLCEngine.</p>
                            <div class="blog-footer">
                                <span class="read-time">15 min read</span>
                                <a href="https://blog.mlc.ai/2024/10/10/optimizing-and-characterizing-high-throughput-low-latency-llm-inference" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>

                    <!-- Article 4: WebLLM -->
                    <article class="blog-card" data-category="research">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fas fa-globe"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Research</span>
                                <span class="blog-date">June 13, 2024</span>
                            </div>
                            <h3>WebLLM: A High-Performance In-Browser LLM Inference Engine</h3>
                            <p>Learn about WebLLM, a high-performance in-browser LLM inference engine that enables zero-server dependency LLM inference on WebGPU.</p>
                            <div class="blog-footer">
                                <span class="read-time">14 min read</span>
                                <a href="https://blog.mlc.ai/2024/06/13/webllm-a-high-performance-in-browser-llm-inference-engine" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>

                    <!-- Article 5: MLC-LLM Universal Deployment -->
                    <article class="blog-card" data-category="deployment">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fas fa-rocket"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Deployment</span>
                                <span class="blog-date">June 7, 2024</span>
                            </div>
                            <h3>MLC-LLM: Universal LLM Deployment Engine with ML Compilation</h3>
                            <p>An overview of MLC-LLM as a universal LLM deployment engine leveraging ML compilation techniques for efficient model deployment across diverse platforms.</p>
                            <div class="blog-footer">
                                <span class="read-time">12 min read</span>
                                <a href="https://blog.mlc.ai/2024/06/07/universal-LLM-deployment-engine-with-ML-compilation" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>

                    <!-- Article 6: Orange Pi GPU -->
                    <article class="blog-card" data-category="tutorials">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fas fa-microchip"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Tutorial</span>
                                <span class="blog-date">April 20, 2024</span>
                            </div>
                            <h3>GPU-Accelerated LLM on a $100 Orange Pi</h3>
                            <p>A practical guide to running GPU-accelerated LLM inference on affordable hardware, demonstrating MLC-LLM's capabilities on budget-friendly devices.</p>
                            <div class="blog-footer">
                                <span class="read-time">10 min read</span>
                                <a href="https://blog.mlc.ai/2024/04/20/GPU-Accelerated-LLM-on-Orange-Pi" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>

                    <!-- Article 7: Multi-GPU Inference -->
                    <article class="blog-card" data-category="optimization">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fas fa-layer-group"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Optimization</span>
                                <span class="blog-date">October 19, 2023</span>
                            </div>
                            <h3>Scalable Language Model Inference on Multiple NVIDIA and AMD GPUs</h3>
                            <p>Explore techniques for scaling language model inference across multiple GPUs from different vendors, enabling efficient distributed inference.</p>
                            <div class="blog-footer">
                                <span class="read-time">16 min read</span>
                                <a href="https://blog.mlc.ai/2023/10/19/Scalable-Language-Model-Inference-on-Multiple-NVDIA-AMD-GPUs" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>

                    <!-- Article 8: AMD GPU Optimization -->
                    <article class="blog-card" data-category="optimization">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fas fa-microchip"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Optimization</span>
                                <span class="blog-date">August 9, 2023</span>
                            </div>
                            <h3>Making AMD GPUs competitive for LLM inference</h3>
                            <p>Technical insights into optimizing LLM inference for AMD GPUs, making them competitive with NVIDIA GPUs for large language model deployment.</p>
                            <div class="blog-footer">
                                <span class="read-time">13 min read</span>
                                <a href="https://blog.mlc.ai/2023/08/09/Making-AMD-GPUs-competitive-for-LLM-inference" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>

                    <!-- Article 9: Consumer Devices -->
                    <article class="blog-card" data-category="deployment">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fas fa-mobile-alt"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Deployment</span>
                                <span class="blog-date">May 22, 2023</span>
                            </div>
                            <h3>Bringing Open Large Language Models to Consumer Devices</h3>
                            <p>Learn how MLC-LLM enables running open large language models on consumer devices, bringing AI capabilities to everyday hardware.</p>
                            <div class="blog-footer">
                                <span class="read-time">11 min read</span>
                                <a href="https://blog.mlc.ai/2023/05/22/bringing-open-large-language-models-to-consumer-devices" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>

                    <!-- Article 10: Android Devices -->
                    <article class="blog-card" data-category="deployment">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fab fa-android"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Deployment</span>
                                <span class="blog-date">May 8, 2023</span>
                            </div>
                            <h3>Bringing Hardware Accelerated Language Models to Android Devices</h3>
                            <p>A comprehensive guide to deploying hardware-accelerated language models on Android devices using MLC-LLM.</p>
                            <div class="blog-footer">
                                <span class="read-time">12 min read</span>
                                <a href="https://blog.mlc.ai/2023/05/08/bringing-hardware-accelerated-language-models-to-android-devices" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>

                    <!-- Article 11: Consumer Hardware -->
                    <article class="blog-card" data-category="deployment">
                        <div class="blog-card-image">
                            <div class="image-placeholder">
                                <i class="fas fa-laptop"></i>
                            </div>
                        </div>
                        <div class="blog-card-content">
                            <div class="blog-meta">
                                <span class="blog-category">Deployment</span>
                                <span class="blog-date">May 1, 2023</span>
                            </div>
                            <h3>Bringing Hardware Accelerated Language Models to Consumer Devices</h3>
                            <p>Early exploration of bringing hardware-accelerated language models to consumer devices, laying the foundation for on-device AI.</p>
                            <div class="blog-footer">
                                <span class="read-time">10 min read</span>
                                <a href="https://blog.mlc.ai/2023/05/01/bringing-accelerated-llm-to-consumer-hardware" class="read-more" target="_blank" rel="noopener">Read More <i class="fas fa-arrow-right"></i></a>
                            </div>
                        </div>
                    </article>
                </div>

                <!-- View All on Blog.mlc.ai -->
                <div class="load-more-container">
                    <a href="https://blog.mlc.ai" class="btn btn-outline load-more-btn" target="_blank" rel="noopener">
                        <i class="fas fa-external-link-alt"></i>
                        View All Posts on blog.mlc.ai
                    </a>
                </div>
            </div>
        </section>

        <!-- Newsletter Subscription -->
        <section class="newsletter-section">
            <div class="container">
                <div class="newsletter-card">
                    <div class="newsletter-content">
                        <h3>Stay Updated</h3>
                        <p>Subscribe to our newsletter for the latest MLC-LLM updates, tutorials, and community highlights.</p>
                        <form class="newsletter-form">
                            <div class="form-group">
                                <input type="email" placeholder="Enter your email address" required>
                                <button type="submit" class="btn btn-primary">
                                    <i class="fas fa-paper-plane"></i>
                                    Subscribe
                                </button>
                            </div>
                        </form>
                        <p class="newsletter-note">No spam, unsubscribe at any time. We respect your privacy.</p>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <div id="site-footer"></div>

    <script src="js/script.js"></script>
</body>
</html>

